# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wy3or8IQreiou-EAc3sKOHpfovP8J4GB
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/heart_attack_prediction_dataset_edit.csv')

df.shape

df.head()

df=df.drop_duplicates(subset=['Patient ID'])

df.dtypes

df.isnull().sum()

category_cols=df.select_dtypes(include='object').columns
for col in category_cols:
  print(df[col].unique())

df.columns

import pandas as pd

try:
    df[['Systolic_Blood Pressure', 'Diastolic_Blood Pressure']] = df['Blood Pressure'].str.split('/', expand=True)
    df['Systolic_Blood Pressure'] = pd.to_numeric(df['Systolic_Blood Pressure'], errors='coerce')
    df['Diastolic_Blood Pressure'] = pd.to_numeric(df['Diastolic_Blood Pressure'], errors='coerce')
    # To see the output, run the code.
    print(df.head())
except:
    print("Error: 'Blood Pressure' column not found or data format is incorrect.")

import numpy as np

for I in ["Age","BMI","Cholesterol","Exercise Hours Per Week","Stress Level","Sedentary Hours Per Day",
          "Income", "BMI", "Triglycerides",  "Physical Activity Days Per Week", "Sleep Hours Per Day",
          "Systolic_Blood Pressure","Diastolic_Blood Pressure"]:

    Q1 = df[I].quantile(0.25)

    Q3 = df[I].quantile(0.75)

    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR

    upper_bound = Q3 + 1.5 * IQR

    df = df[(df[I] >= lower_bound) & (df[I] <= upper_bound)]

print(df.shape)

df['Sex'].fillna(df['Sex'].mode()[0], inplace = True)
df['Sex'] = df['Sex'].replace({'male': 'Male','f': 'Female'})

df['Diet'].fillna(df['Diet'].mode()[0], inplace = True)
df['Diet'] = df['Diet'].replace({'Unhelthy': 'Unhealthy','Healty': 'Healthy'})

df['Diet'].unique()

for i in df.select_dtypes(include='object').columns:
 df[i].fillna(df[i].mode()[0], inplace = True)

for i in df.select_dtypes(include = np.number).columns[:-1]:
 df[i] = df[i].fillna(df[i].mean())

df=df.dropna(subset=['Heart Attack Risk','Patient ID','Blood Pressure','Country'])

# prompt: drop the column 'Heart Attack Risk', 'Patient ID' ,'Blood Pressure'

df = df.drop(columns=[ 'Patient ID', 'Blood Pressure'])

df.isnull().sum()

df.head(30)

category_cols=df.select_dtypes(include='object').columns
for col in category_cols:
  print(df[col].unique())

# prompt: which are categorical columns in this dataset

# Assuming the code you provided has been executed and the DataFrame 'df' is available.

# Identify categorical columns
category_cols = df.select_dtypes(include='object').columns

# Print the unique values for each categorical column
for col in category_cols:
    print(f"Column: {col}, Unique Values: {df[col].unique()}")

# prompt: just give me encoded code for this categorical column

from sklearn.preprocessing import LabelEncoder

# Assuming 'df' and 'category_cols' are already defined as in your previous code

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Encode each categorical column
for col in category_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Print the encoded DataFrame
print(df.head())

for col in df.select_dtypes(include=np.number).columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

#normalize numerial columns
min_max_values = {}
for i in df.select_dtypes(include = np.number).columns[:-1]:
    min_val = df[i].min()
    max_val = df[i].max()
    df[i] = (df[i] - min_val) / (max_val - min_val)
    min_max_values[i] = (min_val, max_val)

min_max_values

import json
with open('min_max_values.json', 'w') as json_file:
    json.dump(min_max_values, json_file)

df.corr()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12,10))
Correlation_matrix = df.corr()
sns.heatmap(Correlation_matrix, annot=True, cmap='coolwarm',fmt='.1f')
plt.title('Correlation Matrix')
plt.show()

x=df.drop(columns=['Heart Attack Risk'],axis=1)
y=df['Heart Attack Risk']

y = df['Heart Attack Risk']
y.value_counts()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Assuming x and y are defined from your previous code
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)


# Define the deep learning model
model = keras.Sequential([
    layers.Dense(15, activation='relu', input_shape=(x_train.shape[1],)),
    layers.Dense(8, activation='relu'),
    layers.Dense(4, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',  # Binary classification loss
              metrics=['accuracy'])

# Train the model
model.fit(x_train_smote, y_train_smote, epochs=10, batch_size=32)

# Evaluate the model
loss, accuracy = model.evaluate(x_test, y_test)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")


# Make predictions on the test set
y_pred_probs = model.predict(x_test)
y_pred = (y_pred_probs > 0.5).astype(int)  # Convert probabilities to class labels


# Evaluate the model
print(classification_report(y_test, y_pred))

conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
conf_matrix

